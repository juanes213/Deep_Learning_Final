Traceback (most recent call last):
  File "C:\Users\pc\AppData\Local\Programs\Python\Python310\lib\site-packages\jupyter_cache\executors\utils.py", line 58, in single_nb_execution
    executenb(
  File "C:\Users\pc\AppData\Local\Programs\Python\Python310\lib\site-packages\nbclient\client.py", line 1314, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "C:\Users\pc\AppData\Local\Programs\Python\Python310\lib\site-packages\jupyter_core\utils\__init__.py", line 165, in wrapped
    return loop.run_until_complete(inner)
  File "C:\Users\pc\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 646, in run_until_complete
    return future.result()
  File "C:\Users\pc\AppData\Local\Programs\Python\Python310\lib\site-packages\nbclient\client.py", line 709, in async_execute
    await self.async_execute_cell(
  File "C:\Users\pc\AppData\Local\Programs\Python\Python310\lib\site-packages\nbclient\client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "C:\Users\pc\AppData\Local\Programs\Python\Python310\lib\site-packages\nbclient\client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------


class Data:
    def __init__(self, file, t, target):
        t = t * 25
        file = (file.sort_values(by='time index')).reset_index(drop=True)
        self.X_train = (file.drop(target, axis='columns')).iloc[:-t]
        self.y_train = file[target].iloc[:-t]
        self.X_test = (file.drop(target, axis='columns')).iloc[-t:]
        self.y_test = file[target].iloc[-t:]

def calcular_metricas(y_true, y_pred):
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
    ss_res = np.sum((y_true - y_pred) ** 2)
    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)
    r2 = 1 - (ss_res / ss_tot)
    lb_test = acorr_ljungbox(y_true - y_pred, lags=[10], return_df=True)
    ljung_box_p_value = lb_test['lb_pvalue'].iloc[0]
    jb_test = jarque_bera(y_true - y_pred)
    jarque_bera_p_value = jb_test[1]
    return {'RMSE': rmse, 'MAPE': mape, 'R2': r2, 'ljung-box': ljung_box_p_value, 'Jarque-bera': jarque_bera_p_value}

def return_of_df(s, e, t):
    target = 'mag_y'
    data_frames = []
    for u in range(1, 6):
        temp_path = f"fisioterapia_dataset_regresion/s{s}/e{e}/u{u}/template_session.txt"
        if os.path.exists(temp_path):
            try:
                temp_file = pd.read_csv(temp_path, delimiter=";")
                data_frames.append(temp_file)
            except Exception:
                pass
    final_data = pd.concat(data_frames, ignore_index=True)
    data = Data(final_data, t, target)
    return data

# FunciÃ³n para crear modelos
def create_model(input_dim, neurons, dropout_rate, model_type):
    model = Sequential()
    if model_type == 'MLP':
        model.add(Dense(neurons, activation='relu', input_shape=(input_dim,)))
        model.add(Dropout(dropout_rate))
    elif model_type == 'RNN':
        model.add(SimpleRNN(neurons, activation='tanh', input_shape=(None, input_dim)))
        model.add(Dropout(dropout_rate))
    elif model_type == 'LSTM':
        model.add(LSTM(neurons, activation='tanh', input_shape=(None, input_dim)))
        model.add(Dropout(dropout_rate))
    model.add(Dense(1, activation='linear'))
    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])
    return model

# FunciÃ³n de entrenamiento con historial (corregida)
def train_and_evaluate_with_history(data, neurons, dropout_rate, batch_size, model_type, epochs=50):
    scaler_X = MinMaxScaler()
    scaler_y = MinMaxScaler()

    # Escalar datos
    X_train = scaler_X.fit_transform(data.X_train)
    y_train = scaler_y.fit_transform(data.y_train.values.reshape(-1, 1))
    X_test = scaler_X.transform(data.X_test)
    y_test = scaler_y.transform(data.y_test.values.reshape(-1, 1))

    # Ajustar la forma segÃºn el modelo
    if model_type in ['RNN', 'LSTM']:
        # Formato para modelos recurrentes
        X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))
        X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))
    else:
        # Formato para MLP
        X_train = X_train.reshape((X_train.shape[0], X_train.shape[1]))
        X_test = X_test.reshape((X_test.shape[0], X_test.shape[1]))

    # Crear el modelo
    model = create_model(input_dim=X_train.shape[-1], neurons=neurons, dropout_rate=dropout_rate, model_type=model_type)

    # Entrenar el modelo
    history = model.fit(
        X_train, y_train,
        validation_data=(X_test, y_test),
        epochs=epochs,
        batch_size=batch_size,
        verbose=0
    )

    # PredicciÃ³n y mÃ©tricas
    y_pred = model.predict(X_test)
    y_pred = scaler_y.inverse_transform(y_pred)
    y_test = scaler_y.inverse_transform(y_test)

    metrics = calcular_metricas(y_test, y_pred)
    return model, metrics, history


def k_fold_evaluation_and_plot(data, model_type, neurons, dropout_rate, batch_size, epochs=50, k=5):
    kfold = KFold(n_splits=k, shuffle=True, random_state=42)
    train_errors, val_errors, test_errors = [], [], []

    for train_idx, val_idx in kfold.split(data.X_train):
        X_train, X_val = data.X_train.iloc[train_idx], data.X_train.iloc[val_idx]
        y_train, y_val = data.y_train.iloc[train_idx], data.y_train.iloc[val_idx]

        fold_data = Data(file=data.X_train.join(data.y_train), t=len(val_idx), target=data.y_train.name)
        fold_data.X_train, fold_data.X_test = X_train, X_val
        fold_data.y_train, fold_data.y_test = y_train, y_val

        model, metrics, history = train_and_evaluate_with_history(fold_data, neurons, dropout_rate, batch_size, model_type, epochs)

        train_errors.extend(history.history['loss'])
        val_errors.extend(history.history['val_loss'])
        test_errors.append(metrics['RMSE'])

        plt.plot(history.history['loss'], label='Train Loss')
        plt.plot(history.history['val_loss'], label='Validation Loss')
        plt.title("Training vs Validation Loss")
        plt.xlabel('Epochs')
        plt.ylabel('Loss')
        plt.legend()
        plt.show()

    plt.boxplot([train_errors, val_errors, test_errors], labels=['Train', 'Validation', 'Test'])
    plt.title('Boxplots of Errors')
    plt.ylabel('Error')
    plt.show()

    return train_errors, val_errors, test_errors

def hyperparameter_search_with_plots(sujeto, ejercicio, model_type, epochs=50):
    dropout_rates = [0.2, 0.8]
    neurons_options = [10]
    batch_sizes = [16, 32]

    for dropout_rate in dropout_rates:
        for neurons in neurons_options:
            for batch_size in batch_sizes:
                for t in [7, 14, 21, 28]:
                    data = return_of_df(sujeto, ejercicio, t)
                    train_errors, val_errors, test_errors = k_fold_evaluation_and_plot(
                        data, model_type, neurons, dropout_rate, batch_size, epochs, k=5
                    )
                    print(f"Train Errors Median: {np.median(train_errors)}, Validation Errors Median: {np.median(val_errors)}, Test Errors Median: {np.median(test_errors)}")

# Llamada de ejemplo
hyperparameter_search_with_plots(sujeto=1, ejercicio=1, model_type='MLP', epochs=50)
hyperparameter_search_with_plots(sujeto=1, ejercicio=1, model_type='LSTM', epochs=50)
hyperparameter_search_with_plots(sujeto=1, ejercicio=1, model_type='RNN', epochs=50)

------------------


[1;31m---------------------------------------------------------------------------[0m
[1;31mValueError[0m                                Traceback (most recent call last)
Cell [1;32mIn [3], line 146[0m
[0;32m    143[0m                     [38;5;28mprint[39m([38;5;124mf[39m[38;5;124m"[39m[38;5;124mTrain Errors Median: [39m[38;5;132;01m{[39;00mnp[38;5;241m.[39mmedian(train_errors)[38;5;132;01m}[39;00m[38;5;124m, Validation Errors Median: [39m[38;5;132;01m{[39;00mnp[38;5;241m.[39mmedian(val_errors)[38;5;132;01m}[39;00m[38;5;124m, Test Errors Median: [39m[38;5;132;01m{[39;00mnp[38;5;241m.[39mmedian(test_errors)[38;5;132;01m}[39;00m[38;5;124m"[39m)
[0;32m    145[0m [38;5;66;03m# Llamada de ejemplo[39;00m
[1;32m--> 146[0m hyperparameter_search_with_plots(sujeto[38;5;241m=[39m[38;5;241m1[39m, ejercicio[38;5;241m=[39m[38;5;241m1[39m, model_type[38;5;241m=[39m[38;5;124m'[39m[38;5;124mMLP[39m[38;5;124m'[39m, epochs[38;5;241m=[39m[38;5;241m50[39m)
[0;32m    147[0m hyperparameter_search_with_plots(sujeto[38;5;241m=[39m[38;5;241m1[39m, ejercicio[38;5;241m=[39m[38;5;241m1[39m, model_type[38;5;241m=[39m[38;5;124m'[39m[38;5;124mLSTM[39m[38;5;124m'[39m, epochs[38;5;241m=[39m[38;5;241m50[39m)
[0;32m    148[0m hyperparameter_search_with_plots(sujeto[38;5;241m=[39m[38;5;241m1[39m, ejercicio[38;5;241m=[39m[38;5;241m1[39m, model_type[38;5;241m=[39m[38;5;124m'[39m[38;5;124mRNN[39m[38;5;124m'[39m, epochs[38;5;241m=[39m[38;5;241m50[39m)

Cell [1;32mIn [3], line 139[0m, in [0;36mhyperparameter_search_with_plots[1;34m(sujeto, ejercicio, model_type, epochs)[0m
[0;32m    137[0m [38;5;28;01mfor[39;00m batch_size [38;5;129;01min[39;00m batch_sizes:
[0;32m    138[0m     [38;5;28;01mfor[39;00m t [38;5;129;01min[39;00m [[38;5;241m7[39m, [38;5;241m14[39m, [38;5;241m21[39m, [38;5;241m28[39m]:
[1;32m--> 139[0m         data [38;5;241m=[39m [43mreturn_of_df[49m[43m([49m[43msujeto[49m[43m,[49m[43m [49m[43mejercicio[49m[43m,[49m[43m [49m[43mt[49m[43m)[49m
[0;32m    140[0m         train_errors, val_errors, test_errors [38;5;241m=[39m k_fold_evaluation_and_plot(
[0;32m    141[0m             data, model_type, neurons, dropout_rate, batch_size, epochs, k[38;5;241m=[39m[38;5;241m5[39m
[0;32m    142[0m         )
[0;32m    143[0m         [38;5;28mprint[39m([38;5;124mf[39m[38;5;124m"[39m[38;5;124mTrain Errors Median: [39m[38;5;132;01m{[39;00mnp[38;5;241m.[39mmedian(train_errors)[38;5;132;01m}[39;00m[38;5;124m, Validation Errors Median: [39m[38;5;132;01m{[39;00mnp[38;5;241m.[39mmedian(val_errors)[38;5;132;01m}[39;00m[38;5;124m, Test Errors Median: [39m[38;5;132;01m{[39;00mnp[38;5;241m.[39mmedian(test_errors)[38;5;132;01m}[39;00m[38;5;124m"[39m)

Cell [1;32mIn [3], line 35[0m, in [0;36mreturn_of_df[1;34m(s, e, t)[0m
[0;32m     33[0m         [38;5;28;01mexcept[39;00m [38;5;167;01mException[39;00m:
[0;32m     34[0m             [38;5;28;01mpass[39;00m
[1;32m---> 35[0m final_data [38;5;241m=[39m [43mpd[49m[38;5;241;43m.[39;49m[43mconcat[49m[43m([49m[43mdata_frames[49m[43m,[49m[43m [49m[43mignore_index[49m[38;5;241;43m=[39;49m[38;5;28;43;01mTrue[39;49;00m[43m)[49m
[0;32m     36[0m data [38;5;241m=[39m Data(final_data, t, target)
[0;32m     37[0m [38;5;28;01mreturn[39;00m data

File [1;32m~\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\reshape\concat.py:380[0m, in [0;36mconcat[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)[0m
[0;32m    377[0m [38;5;28;01melif[39;00m copy [38;5;129;01mand[39;00m using_copy_on_write():
[0;32m    378[0m     copy [38;5;241m=[39m [38;5;28;01mFalse[39;00m
[1;32m--> 380[0m op [38;5;241m=[39m [43m_Concatenator[49m[43m([49m
[0;32m    381[0m [43m    [49m[43mobjs[49m[43m,[49m
[0;32m    382[0m [43m    [49m[43maxis[49m[38;5;241;43m=[39;49m[43maxis[49m[43m,[49m
[0;32m    383[0m [43m    [49m[43mignore_index[49m[38;5;241;43m=[39;49m[43mignore_index[49m[43m,[49m
[0;32m    384[0m [43m    [49m[43mjoin[49m[38;5;241;43m=[39;49m[43mjoin[49m[43m,[49m
[0;32m    385[0m [43m    [49m[43mkeys[49m[38;5;241;43m=[39;49m[43mkeys[49m[43m,[49m
[0;32m    386[0m [43m    [49m[43mlevels[49m[38;5;241;43m=[39;49m[43mlevels[49m[43m,[49m
[0;32m    387[0m [43m    [49m[43mnames[49m[38;5;241;43m=[39;49m[43mnames[49m[43m,[49m
[0;32m    388[0m [43m    [49m[43mverify_integrity[49m[38;5;241;43m=[39;49m[43mverify_integrity[49m[43m,[49m
[0;32m    389[0m [43m    [49m[43mcopy[49m[38;5;241;43m=[39;49m[43mcopy[49m[43m,[49m
[0;32m    390[0m [43m    [49m[43msort[49m[38;5;241;43m=[39;49m[43msort[49m[43m,[49m
[0;32m    391[0m [43m[49m[43m)[49m
[0;32m    393[0m [38;5;28;01mreturn[39;00m op[38;5;241m.[39mget_result()

File [1;32m~\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\reshape\concat.py:443[0m, in [0;36m_Concatenator.__init__[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)[0m
[0;32m    440[0m [38;5;28mself[39m[38;5;241m.[39mverify_integrity [38;5;241m=[39m verify_integrity
[0;32m    441[0m [38;5;28mself[39m[38;5;241m.[39mcopy [38;5;241m=[39m copy
[1;32m--> 443[0m objs, keys [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_clean_keys_and_objs[49m[43m([49m[43mobjs[49m[43m,[49m[43m [49m[43mkeys[49m[43m)[49m
[0;32m    445[0m [38;5;66;03m# figure out what our result ndim is going to be[39;00m
[0;32m    446[0m ndims [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39m_get_ndims(objs)

File [1;32m~\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\reshape\concat.py:505[0m, in [0;36m_Concatenator._clean_keys_and_objs[1;34m(self, objs, keys)[0m
[0;32m    502[0m     objs_list [38;5;241m=[39m [38;5;28mlist[39m(objs)
[0;32m    504[0m [38;5;28;01mif[39;00m [38;5;28mlen[39m(objs_list) [38;5;241m==[39m [38;5;241m0[39m:
[1;32m--> 505[0m     [38;5;28;01mraise[39;00m [38;5;167;01mValueError[39;00m([38;5;124m"[39m[38;5;124mNo objects to concatenate[39m[38;5;124m"[39m)
[0;32m    507[0m [38;5;28;01mif[39;00m keys [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m:
[0;32m    508[0m     objs_list [38;5;241m=[39m [38;5;28mlist[39m(com[38;5;241m.[39mnot_none([38;5;241m*[39mobjs_list))

[1;31mValueError[0m: No objects to concatenate

